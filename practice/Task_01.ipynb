{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e900e7-56a6-496d-8cc9-9e9b43b09d3a",
   "metadata": {},
   "source": [
    "# Выполнение задания 1\n",
    "### Изменения прописаны капсом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9370c079-62fd-4132-b7f2-4a2d24c323a5",
   "metadata": {},
   "source": [
    "### Импортируем необходимые пакеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ba5ae4-be99-40f8-af30-811f5db425b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321238c9-97ce-4e3c-aae2-9b91b87cf2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем готовый класс от торча для загрузки данных для тренировки\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    \"./mnist/\", train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "mnist_val = torchvision.datasets.MNIST(\n",
    "    \"./mnist/\", train=False, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# так как это уже унаследованный от Dataset класс, его можно сразу обернуть в даталоадер\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_train, batch_size=64, shuffle=True, num_workers=1  # 64 ДАЁТ МЕНЕЕ ШУМНЫЕ ГРАДИЕНТЫ\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_val, batch_size=64, shuffle=False, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d2950f8-6542-42ca-8c06-f52e3210af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),  # ИСПОЛЬЗУЮ СНС (ЛУЧШЕ БЫ КЛАСС, НО ОСТАВЛЮ ЭТО НА СЛЕД. ЗАДАЧИ)\n",
    "    nn.ReLU(),  # ДОБАВЛЯЕМ НЕЛИНЕЙНОСТЬ\n",
    "    nn.MaxPool2d(2),  # ПОНИЖАЕМ РАЗМЕРНОСТЬ 28x28 -> 14x14\n",
    "    # ВТОРОЙ БЛОК\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),  # 14x14 -> 7x7\n",
    "\n",
    "    nn.Flatten(),  # превращаем картинку 28х28 в вектор размером 784\n",
    "    nn.Linear(\n",
    "        64 * 7 * 7, 128  # ДОБАВЛЯЕМ УМНОЖЕНИЕ НА КОЛИЧЕСТВО КАНАЛОВ\n",
    "    ),  # линейный слой, преобразующий вектор размера 784 в вектор размера 128\n",
    "    nn.ReLU(),  # нелинейность\n",
    "    nn.Linear(\n",
    "        128, 10\n",
    "    ),  # линейный слой, преобразующий вектор размера 128 в вектор размера 10\n",
    ")\n",
    "\n",
    "# создаем оптимизатор, который будет обновлять веса модели\n",
    "# AdamW ОБЕСПЕЧИВАЕТ СТАБИЛЬНОЕ ОБНОВЛЕНИЕ ПАРАМЕТРОВ\n",
    "# lr=0.001 СОГЛАСНО ЭМПИРИЧЕСКИМ ПРАВИЛАМ\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "# АДАПТИРУЕТ СКОРОСТЬ ОБУЧЕНИЯ\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', patience=3, factor=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2b152-bd8d-4b17-a235-6049b7ec7c48",
   "metadata": {},
   "source": [
    "### Изменения прописаны капсом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d7a5b2-cab3-465f-b815-f69dc8830ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a6e2424fc44af38a37f6f2672c2742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8b601ad24c40f684b9b4811e4a630d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.046054091304540634, accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2147696dc5204ee79c8d61c0c9060c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f2091d51b745168d6930bb4b6838c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d05e08c18354404b7bf2768b6dfdabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.027880780398845673, accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c4d120288a4d91b1a5fb14f1b06065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e00742f94314a70bda13f5536821aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ef07919a974b1381f242645e3d2248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.03223597630858421, accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # МОЖНО СОКРАТИТЬ ДО 3, Т.К. accuracy НЕ МЕНЯТСЯ ПОСЛЕ 3 ПРОГОНА\n",
    "    for x_train, y_train in tqdm(train_dataloader):  # берем батч из трейн лоадера\n",
    "        y_pred = model(x_train)  # делаем предсказания\n",
    "        loss = F.cross_entropy(y_pred, y_train)  # считаем лосс\n",
    "        loss.backward()  # считаем градиенты обратным проходом\n",
    "        optimizer.step()  # обновляем параметры сети\n",
    "        optimizer.zero_grad()  # обнуляем посчитанные градиенты параметров\n",
    "\n",
    "    model.eval()  # ВКЛЮЧАЕМ РЕЖИМ ОЦЕНКИ\n",
    "    if epoch % 2 == 0:\n",
    "        val_loss = []  # сюда будем складывать **средний по бачу** лосс\n",
    "        val_accuracy = []\n",
    "        with torch.no_grad():  # на валидации запрещаем фреймворку считать градиенты по параметрам\n",
    "            for x_val, y_val in tqdm(\n",
    "                val_dataloader\n",
    "            ):  # берем батч из валидационного лоадера\n",
    "                y_pred = model(x_val)  # делаем предсказания\n",
    "                loss = F.cross_entropy(y_pred, y_val)  # считаем лосс\n",
    "                val_loss.append(loss.numpy())  # добавляем в массив\n",
    "                val_accuracy.extend(\n",
    "                    (torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist()\n",
    "                )\n",
    "        scheduler.step(np.mean(val_loss))  # ОБНОВЛЕНИЕ lr\n",
    "        # печатаем метрики\n",
    "        print(\n",
    "            f\"Epoch: {epoch}, loss: {np.mean(val_loss)}, accuracy: {np.mean(val_accuracy)}\"\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4302d33d-0396-4c47-86fd-309ca29b5977",
   "metadata": {},
   "source": [
    "Тем самым accuracy увеличилась с 0.9775 до 0.9898"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
